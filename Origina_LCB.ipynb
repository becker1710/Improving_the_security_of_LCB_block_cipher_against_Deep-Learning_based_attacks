{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1#Header\n",
    "import csv\n",
    "import numpy as np\n",
    "import os \n",
    "from os import urandom\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2#Defining Global Variables\n",
    "num_rounds = 10\n",
    "m = 0\n",
    "o = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3#Defining WORDSIZE\n",
    "def WORD_SIZE():\n",
    "    return(16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4#Defining S-Box\n",
    "s_box_mapping_np = np.array([0, 4, 1, 5, 2, 6, 3, 7, 8, 12, 9, 13, 10, 14, 11, 15], dtype=np.uint8)\n",
    "\n",
    "def s_box(input_bits):\n",
    "    input_bits_int = int(input_bits)\n",
    "    output_bits_int = s_box_mapping_np[input_bits_int]\n",
    "    return output_bits_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5#Defining P-Box\n",
    "def decimal_to_binary_list(value, num_bits=4):\n",
    "    return np.array([int(x) for x in format(value, f'0{num_bits}b')], dtype=np.uint8)\n",
    "\n",
    "def p_box(c_decimal, d_decimal):\n",
    "    c = decimal_to_binary_list(c_decimal)\n",
    "    d = decimal_to_binary_list(d_decimal)\n",
    "\n",
    "    e = np.zeros(8, dtype=np.uint8)\n",
    "\n",
    "    e[0] = c[0]\n",
    "    e[1] = d[0]\n",
    "    e[2] = c[3]\n",
    "    e[3] = d[3]\n",
    "    e[4] = c[1]\n",
    "    e[5] = d[1]\n",
    "    e[6] = c[2]\n",
    "    e[7] = d[2]\n",
    "\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6#Defining L-Box\n",
    "def l_box(f, g):\n",
    "    if len(f) != 8 or len(g) != 8:\n",
    "        raise ValueError(\"Both input arrays f and g should have exactly 8 elements\")\n",
    "\n",
    "    h = np.zeros(16, dtype=np.uint8)\n",
    "    h[0] = f[0]\n",
    "    h[1] = g[0]\n",
    "    h[2] = f[7]\n",
    "    h[3] = g[7]\n",
    "    h[4] = f[1]\n",
    "    h[5] = g[1]\n",
    "    h[6] = f[6]\n",
    "    h[7] = g[6]\n",
    "    h[8] = f[2]\n",
    "    h[9] = g[2]\n",
    "    h[10] = f[5]\n",
    "    h[11] = g[5]\n",
    "    h[12] = f[3]\n",
    "    h[13] = g[3]\n",
    "    h[14] = f[4]\n",
    "    h[15] = g[4]\n",
    "    #print(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7#Defining F-function for Right Side of Plaintext\n",
    "def binary_array_to_integer(output):\n",
    "    int_output = ''.join(map(str, output))\n",
    "    return int(int_output, 2)\n",
    "\n",
    "def f_function(x, key, d):\n",
    "    q=0\n",
    "    global m\n",
    "    if isinstance(x, int):\n",
    "        x = [x]\n",
    "    input_parts = np.zeros((len(x), 4), dtype=np.uint16)\n",
    "    for i, val in enumerate(x):\n",
    "        input_parts[i] = np.array([val >> 12, (val >> 8) & 0xF, (val >> 4) & 0xF, val & 0xF])\n",
    "    \n",
    "    s_box_outputs = np.array([[s_box(element) for element in part] for part in input_parts])\n",
    "    p_box_outputs = np.zeros((len(x), 2, 8), dtype=np.uint8)\n",
    "    for i in range(len(x)):\n",
    "        p_box_outputs[i] = np.array([p_box(s_box_outputs[i][0], s_box_outputs[i][1]), p_box(s_box_outputs[i][2], s_box_outputs[i][3])])\n",
    "    \n",
    "    final_outputs = np.zeros(len(x), dtype=np.uint32)\n",
    "    for i in range(len(x)):\n",
    "        final_output = np.array(l_box(p_box_outputs[i][0], p_box_outputs[i][1]))\n",
    "        k = key[q][(m+1) % 4]\n",
    "        output = final_output ^ k\n",
    "        output = binary_array_to_integer(output)\n",
    "        final_outputs[i] = output\n",
    "        q +=1 \n",
    "    if (m < 2):\n",
    "            m +=2\n",
    "    else:\n",
    "            m = 0\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8#Defining F-function for Left Side of Plaintext\n",
    "def binary_array_to_integer(output):\n",
    "    int_output = ''.join(map(str, output))\n",
    "    return int(int_output, 2)\n",
    "\n",
    "def ff_function(x, key, d):\n",
    "    q=0\n",
    "    global o\n",
    "    if isinstance(x, int):\n",
    "        x = [x]\n",
    "        \n",
    "    input_parts = np.zeros((len(x), 4), dtype=np.uint16)\n",
    "    for i, val in enumerate(x):\n",
    "        input_parts[i] = np.array([val >> 12, (val >> 8) & 0xF, (val >> 4) & 0xF, val & 0xF])\n",
    "   \n",
    "    s_box_outputs = np.array([[s_box(element) for element in part] for part in input_parts])\n",
    "    p_box_outputs = np.zeros((len(x), 2, 8), dtype=np.uint8)\n",
    "    for i in range(len(x)):\n",
    "        p_box_outputs[i] = np.array([p_box(s_box_outputs[i][0], s_box_outputs[i][1]), p_box(s_box_outputs[i][2], s_box_outputs[i][3])])\n",
    "    \n",
    "    final_outputs = np.zeros(len(x), dtype=np.uint32)\n",
    "    for i in range(len(x)):\n",
    "        final_output = np.array(l_box(p_box_outputs[i][0], p_box_outputs[i][1]))\n",
    "        k = key[q][o % 4]\n",
    "        output = final_output ^ k\n",
    "        output = binary_array_to_integer(output)\n",
    "        final_outputs[i] = output\n",
    "        q +=1 \n",
    "    if (o < 2):\n",
    "            o +=2\n",
    "    else:\n",
    "            o = 0\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9#Convert the ciphertext pairs into Binary array\n",
    "def convert_to_binary(row):\n",
    "    bin_array = np.zeros(64, dtype=np.uint8)\n",
    "    for i, num in enumerate(row):\n",
    "        binary_str = format(num, '016b')\n",
    "        for j, b in enumerate(binary_str):\n",
    "            bin_array[i * 16 + j] = int(b)\n",
    "    return bin_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10#Encryption Function\n",
    "def lcb_encrypt(plaintext, key, rounds, d):\n",
    "    \n",
    "    left_plaintext = np.uint16(plaintext[0])\n",
    "    right_plaintext = np.uint16(plaintext[1])\n",
    "    L, R = left_plaintext, right_plaintext\n",
    "\n",
    "    n = 0\n",
    "    \n",
    "    while n < rounds:\n",
    "        L, R = f_function(R, key, d), ff_function(L, key, d)\n",
    "        n += 1\n",
    "    print(\"Encryption done per round\")    \n",
    "    return (L, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11#Fuction for generation of keys\n",
    "import random\n",
    "\n",
    "def generate_hex_keys(num_keys, length=16):\n",
    "    hex_chars = \"0123456789ABCDEF\"\n",
    "    keys_str = [\"\".join(random.choices(hex_chars, k=length)) for _ in range(num_keys)]\n",
    "\n",
    "    return keys_str\n",
    "\n",
    "\n",
    "def to_binary(value, bits):\n",
    "    return format(value, f'0{bits}b')\n",
    "\n",
    "def generate_round_keys(num_keys):\n",
    "    random_keys_hex = generate_hex_keys(num_keys)\n",
    "    round_keys = []\n",
    "    \n",
    "    for random_key_hex in random_keys_hex:\n",
    "        random_key = int(random_key_hex, 16)\n",
    "\n",
    "        K1 = (random_key >> 48) & 0xFFFF\n",
    "        K2 = (random_key >> 32) & 0xFFFF\n",
    "        K3 = (random_key >> 16) & 0xFFFF\n",
    "        K4 = random_key & 0xFFFF\n",
    "        \n",
    "        k1_bin = to_binary(K1, 16)\n",
    "        k2_bin = to_binary(K2, 16)\n",
    "        k3_bin = to_binary(K3, 16)\n",
    "        k4_bin = to_binary(K4, 16)\n",
    "\n",
    "        k1_np_array = np.array([int(bit) for bit in k1_bin])\n",
    "        k2_np_array = np.array([int(bit) for bit in k2_bin])\n",
    "        k3_np_array = np.array([int(bit) for bit in k3_bin])\n",
    "        k4_np_array = np.array([int(bit) for bit in k4_bin])\n",
    "\n",
    "        round_key = np.array([k1_np_array, k2_np_array, k3_np_array, k4_np_array])\n",
    "        round_keys.append(round_key)\n",
    "    round_key = np.array(round_keys)\n",
    "    print(\"Key generation done\")\n",
    "    return round_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12#Make dataset\n",
    "\n",
    "def make_train_data(n, nr, diff=(0,0x836F)):\n",
    "  Y = np.frombuffer(urandom(n), dtype=np.uint8);\n",
    "  Y = Y & 1;\n",
    "  plaintext = np.frombuffer(urandom(4*n), dtype=np.uint32);\n",
    "  plain0l = np.empty(n, dtype=np.uint16)\n",
    "  plain0r = np.empty(n, dtype=np.uint16)\n",
    "  \n",
    "  for i in range(n):\n",
    "    plain0l[i] = (plaintext[i] >> 16) & 0xffff\n",
    "    plain0r[i] = plaintext[i] & 0xffff\n",
    "  \n",
    "  plain1l = plain0l ^ diff[0]; plain1r = plain0r ^ diff[1];\n",
    "  \n",
    "  num_rand_samples = np.sum(Y==0);\n",
    "  plain1l[Y==0] = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  plain1r[Y==0] = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  \n",
    "  round_key = generate_round_keys(n)\n",
    "  \n",
    "  ctdata0l, ctdata0r = lcb_encrypt((plain0l, plain0r), round_key, nr, n)\n",
    "  ctdata1l, ctdata1r = lcb_encrypt((plain1l, plain1r), round_key, nr, n)\n",
    "  print(\"All encryption done\")\n",
    "  ctdata = np.vstack((ctdata0l, ctdata0r, ctdata1l, ctdata1r)).T\n",
    "  X = np.array([convert_to_binary(row) for row in ctdata])\n",
    "  print(X)\n",
    "  return(X,Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13#Creation of Model\n",
    "\n",
    "from pickle import dump\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import Dense, Conv1D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dropout\n",
    "\n",
    "dropout_rate = 0.5;\n",
    "bs = 2000;\n",
    "wdir = './freshly_trained_nets/'\n",
    "\n",
    "def cyclic_lr(num_epochs, high_lr, low_lr):\n",
    "  res = lambda i: low_lr + ((num_epochs-1) - i % num_epochs)/(num_epochs-1) * (high_lr - low_lr);\n",
    "  return(res);\n",
    "\n",
    "def make_checkpoint(datei):\n",
    "  res = ModelCheckpoint(datei, monitor='val_loss', save_best_only = True);\n",
    "  return(res);\n",
    "\n",
    "#make residual tower of convolutional blocks\n",
    "def make_resnet(num_blocks=2, num_filters=32, num_outputs=1, d1=64, d2=64, word_size=16, ks=3,depth=5, reg_param=0.0001, final_activation='sigmoid'):\n",
    "  #Input and preprocessing layers\n",
    "  inp = Input(shape=(num_blocks * word_size * 2,));\n",
    "  rs = Reshape((2 * num_blocks, word_size))(inp);\n",
    "  perm = Permute((2,1))(rs);\n",
    "  #add a single residual layer that will expand the data to num_filters channels\n",
    "  #this is a bit-sliced layer\n",
    "  conv0 = Conv1D(num_filters, kernel_size=1, padding='same', kernel_regularizer=l2(reg_param))(perm);\n",
    "  conv0 = BatchNormalization()(conv0);\n",
    "  conv0 = Activation('relu')(conv0);\n",
    "  #add residual blocks\n",
    "  shortcut = conv0;\n",
    "  for i in range(depth):\n",
    "    conv1 = Conv1D(num_filters, kernel_size=ks, padding='same', kernel_regularizer=l2(reg_param))(shortcut);\n",
    "    conv1 = BatchNormalization()(conv1);\n",
    "    conv1 = Activation('relu')(conv1);\n",
    "    conv2 = Conv1D(num_filters, kernel_size=ks, padding='same',kernel_regularizer=l2(reg_param))(conv1);\n",
    "    conv2 = BatchNormalization()(conv2);\n",
    "    conv2 = Activation('relu')(conv2);\n",
    "    conv2 = Dropout(dropout_rate)(conv2)\n",
    "    shortcut = Add()([shortcut, conv2]);\n",
    "    \n",
    "  #add prediction head\n",
    "  flat1 = Flatten()(shortcut);\n",
    "  dense1 = Dense(d1,kernel_regularizer=l2(reg_param))(flat1);\n",
    "  dense1 = BatchNormalization()(dense1);\n",
    "  dense1 = Activation('relu')(dense1);\n",
    "  dense1 = Dropout(dropout_rate)(dense1)  # Add dropout layer after the first dense layer\n",
    "  dense2 = Dense(d2, kernel_regularizer=l2(reg_param))(dense1);\n",
    "  dense2 = Dropout(dropout_rate)(dense2)\n",
    "  dense2 = BatchNormalization()(dense2);\n",
    "  dense2 = Activation('relu')(dense2);\n",
    "  out = Dense(num_outputs, activation=final_activation, kernel_regularizer=l2(reg_param))(dense2);\n",
    "  model = Model(inputs=inp, outputs=out);\n",
    "  return(model);\n",
    "\n",
    "def train_LCB_distinguisher(num_epochs, num_rounds, depth):\n",
    "    #create the network\n",
    "    print(num_rounds)\n",
    "    print(depth)\n",
    "    net = make_resnet(depth=depth, reg_param=0.00007);\n",
    "    opt = SGD(learning_rate=0.00001, momentum=0.5)\n",
    "    net.compile(optimizer= opt,loss='binary_crossentropy',metrics=['acc']);\n",
    "    #net.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc']);\n",
    "    #generate training and validation data\n",
    "    X, Y = make_train_data(10000000,num_rounds);\n",
    "    X_eval, Y_eval = make_train_data(1000000, num_rounds);\n",
    "    #set up model checkpoint\n",
    "    check = make_checkpoint(wdir+'FINAL_VULNERABLE_'+str(num_rounds)+'_depth_'+str(depth)+'.h5');\n",
    "    #create learnrate schedule\n",
    "    lr = LearningRateScheduler(cyclic_lr(10,0.00004, 0.000019));\n",
    "    #train and evaluate\n",
    "    #print(X_eval)\n",
    "    h = net.fit(X,Y,epochs=num_epochs,batch_size=bs,validation_data=(X_eval, Y_eval), callbacks=[lr,check]);\n",
    "    np.save(wdir+'h'+str(num_rounds)+'r_depth'+str(depth)+'.npy', h.history['val_acc']);\n",
    "    np.save(wdir+'h'+str(num_rounds)+'r_depth'+str(depth)+'.npy', h.history['val_loss']);\n",
    "    dump(h.history,open(wdir+'hist'+str(num_rounds)+'r_depth'+str(depth)+'.p','wb'));\n",
    "    print(\"Best validation accuracy: \", np.max(h.history['val_acc']));\n",
    "    return(net, h);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "3\n",
      "Key generation done\n",
      "Encryption done per round\n",
      "Encryption done per round\n",
      "All encryption done\n",
      "[[0 0 0 ... 0 0 1]\n",
      " [1 0 1 ... 0 1 1]\n",
      " [0 0 0 ... 1 1 1]\n",
      " ...\n",
      " [1 0 0 ... 1 0 0]\n",
      " [1 1 1 ... 0 1 0]\n",
      " [1 1 0 ... 1 1 1]]\n",
      "Key generation done\n",
      "Encryption done per round\n",
      "Encryption done per round\n",
      "All encryption done\n",
      "[[1 0 0 ... 1 0 1]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 1 1 1]\n",
      " ...\n",
      " [1 0 1 ... 0 1 0]\n",
      " [0 1 0 ... 0 1 1]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "Epoch 1/30\n",
      "5000/5000 [==============================] - 691s 138ms/step - loss: 0.7995 - acc: 0.5066 - val_loss: 0.7048 - val_acc: 0.5933 - lr: 4.0000e-05\n",
      "Epoch 2/30\n",
      "5000/5000 [==============================] - 688s 138ms/step - loss: 0.7546 - acc: 0.5421 - val_loss: 0.6739 - val_acc: 0.6609 - lr: 3.7667e-05\n",
      "Epoch 3/30\n",
      "5000/5000 [==============================] - 684s 137ms/step - loss: 0.7116 - acc: 0.5827 - val_loss: 0.6429 - val_acc: 0.7012 - lr: 3.5333e-05\n",
      "Epoch 4/30\n",
      "5000/5000 [==============================] - 684s 137ms/step - loss: 0.6647 - acc: 0.6314 - val_loss: 0.6113 - val_acc: 0.7297 - lr: 3.3000e-05\n",
      "Epoch 5/30\n",
      "5000/5000 [==============================] - 688s 138ms/step - loss: 0.6155 - acc: 0.6854 - val_loss: 0.5815 - val_acc: 0.7480 - lr: 3.0667e-05\n",
      "Epoch 6/30\n",
      "5000/5000 [==============================] - 681s 136ms/step - loss: 0.5690 - acc: 0.7380 - val_loss: 0.5541 - val_acc: 0.7649 - lr: 2.8333e-05\n",
      "Epoch 7/30\n",
      "5000/5000 [==============================] - 683s 137ms/step - loss: 0.5286 - acc: 0.7830 - val_loss: 0.5305 - val_acc: 0.7770 - lr: 2.6000e-05\n",
      "Epoch 8/30\n",
      "5000/5000 [==============================] - 698s 140ms/step - loss: 0.4944 - acc: 0.8188 - val_loss: 0.5113 - val_acc: 0.7845 - lr: 2.3667e-05\n",
      "Epoch 9/30\n",
      "5000/5000 [==============================] - 679s 136ms/step - loss: 0.4656 - acc: 0.8463 - val_loss: 0.4950 - val_acc: 0.7915 - lr: 2.1333e-05\n",
      "Epoch 10/30\n",
      "5000/5000 [==============================] - 678s 136ms/step - loss: 0.4418 - acc: 0.8665 - val_loss: 0.4802 - val_acc: 0.7983 - lr: 1.9000e-05\n",
      "Epoch 11/30\n",
      "5000/5000 [==============================] - 677s 135ms/step - loss: 0.4095 - acc: 0.8899 - val_loss: 0.4515 - val_acc: 0.8120 - lr: 4.0000e-05\n",
      "Epoch 12/30\n",
      "5000/5000 [==============================] - 673s 135ms/step - loss: 0.3706 - acc: 0.9128 - val_loss: 0.4280 - val_acc: 0.8226 - lr: 3.7667e-05\n",
      "Epoch 13/30\n",
      "5000/5000 [==============================] - 675s 135ms/step - loss: 0.3378 - acc: 0.9279 - val_loss: 0.4057 - val_acc: 0.8342 - lr: 3.5333e-05\n",
      "Epoch 14/30\n",
      "5000/5000 [==============================] - 673s 135ms/step - loss: 0.3105 - acc: 0.9385 - val_loss: 0.3875 - val_acc: 0.8439 - lr: 3.3000e-05\n",
      "Epoch 15/30\n",
      "5000/5000 [==============================] - 673s 135ms/step - loss: 0.2876 - acc: 0.9463 - val_loss: 0.3676 - val_acc: 0.8562 - lr: 3.0667e-05\n",
      "Epoch 16/30\n",
      "5000/5000 [==============================] - 683s 137ms/step - loss: 0.2687 - acc: 0.9520 - val_loss: 0.3545 - val_acc: 0.8629 - lr: 2.8333e-05\n",
      "Epoch 17/30\n",
      "5000/5000 [==============================] - 688s 138ms/step - loss: 0.2530 - acc: 0.9565 - val_loss: 0.3420 - val_acc: 0.8696 - lr: 2.6000e-05\n",
      "Epoch 18/30\n",
      "5000/5000 [==============================] - 695s 139ms/step - loss: 0.2400 - acc: 0.9601 - val_loss: 0.3315 - val_acc: 0.8754 - lr: 2.3667e-05\n",
      "Epoch 19/30\n",
      "5000/5000 [==============================] - 699s 140ms/step - loss: 0.2293 - acc: 0.9628 - val_loss: 0.3222 - val_acc: 0.8805 - lr: 2.1333e-05\n",
      "Epoch 20/30\n",
      "5000/5000 [==============================] - 683s 137ms/step - loss: 0.2205 - acc: 0.9650 - val_loss: 0.3139 - val_acc: 0.8852 - lr: 1.9000e-05\n",
      "Epoch 21/30\n",
      "5000/5000 [==============================] - 697s 139ms/step - loss: 0.2087 - acc: 0.9679 - val_loss: 0.2976 - val_acc: 0.8944 - lr: 4.0000e-05\n",
      "Epoch 22/30\n",
      "5000/5000 [==============================] - 692s 138ms/step - loss: 0.1950 - acc: 0.9711 - val_loss: 0.2853 - val_acc: 0.9004 - lr: 3.7667e-05\n",
      "Epoch 23/30\n",
      "5000/5000 [==============================] - 690s 138ms/step - loss: 0.1837 - acc: 0.9736 - val_loss: 0.2732 - val_acc: 0.9070 - lr: 3.5333e-05\n",
      "Epoch 24/30\n",
      "5000/5000 [==============================] - 682s 136ms/step - loss: 0.1742 - acc: 0.9757 - val_loss: 0.2653 - val_acc: 0.9106 - lr: 3.3000e-05\n",
      "Epoch 25/30\n",
      "5000/5000 [==============================] - 686s 137ms/step - loss: 0.1663 - acc: 0.9774 - val_loss: 0.2564 - val_acc: 0.9153 - lr: 3.0667e-05\n",
      "Epoch 26/30\n",
      "5000/5000 [==============================] - 685s 137ms/step - loss: 0.1596 - acc: 0.9787 - val_loss: 0.2500 - val_acc: 0.9182 - lr: 2.8333e-05\n",
      "Epoch 27/30\n",
      "5000/5000 [==============================] - 678s 136ms/step - loss: 0.1539 - acc: 0.9800 - val_loss: 0.2417 - val_acc: 0.9229 - lr: 2.6000e-05\n",
      "Epoch 28/30\n",
      "5000/5000 [==============================] - 684s 137ms/step - loss: 0.1490 - acc: 0.9810 - val_loss: 0.2367 - val_acc: 0.9251 - lr: 2.3667e-05\n",
      "Epoch 29/30\n",
      "5000/5000 [==============================] - 681s 136ms/step - loss: 0.1449 - acc: 0.9819 - val_loss: 0.2318 - val_acc: 0.9276 - lr: 2.1333e-05\n",
      "Epoch 30/30\n",
      "5000/5000 [==============================] - 678s 136ms/step - loss: 0.1415 - acc: 0.9824 - val_loss: 0.2296 - val_acc: 0.9285 - lr: 1.9000e-05\n",
      "Best validation accuracy:  0.9284650087356567\n"
     ]
    }
   ],
   "source": [
    "#14#Training the Model\n",
    "#1crore, 10lakhs\n",
    "num_epochs = 30\n",
    "depth = 3\n",
    "trained_net, history = train_LCB_distinguisher(num_epochs, num_rounds, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL_VULNERABLE20_depth_3.json\n"
     ]
    }
   ],
   "source": [
    "#15#Create JSON File \n",
    "# Convert the model architecture to JSON format\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "model_json = trained_net.to_json()\n",
    "\n",
    "    # Save the model architecture as a JSON file (optional)\n",
    "filename = f'FINAL_VULNERABLE_10_depth_3.json'\n",
    "print(filename)\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(json.loads(model_json), json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16#Evaluate Function\n",
    "def evaluate(net,X,Y):\n",
    "    Z = net.predict(X,batch_size=4000).flatten();\n",
    "    Zbin = (Z > 0.5);\n",
    "    diff = Y - Z; mse = np.mean(diff*diff);\n",
    "    n = len(Z); n0 = np.sum(Y==0); n1 = np.sum(Y==1);\n",
    "    acc = np.sum(Zbin == Y) / n;\n",
    "    tpr = np.sum(Zbin[Y==1]) / n1;\n",
    "    tnr = np.sum(Zbin[Y==0] == 0) / n0;\n",
    "    mreal = np.median(Z[Y==1]);\n",
    "    high_random = np.sum(Z[Y==0] > mreal) / n0;\n",
    "    print(\"Accuracy: \", acc, \"TPR: \", tpr, \"TNR: \", tnr, \"MSE:\", mse);\n",
    "    print(\"Percentage of random pairs with score higher than median of real pairs:\", 100*high_random);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key generation done\n",
      "Encryption done per round\n",
      "Encryption done per round\n",
      "All encryption done\n",
      "[[0 1 0 ... 0 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [1 1 0 ... 1 1 1]\n",
      " ...\n",
      " [0 1 1 ... 0 0 1]\n",
      " [1 0 0 ... 1 1 0]\n",
      " [0 1 0 ... 0 1 0]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19152\\453632193.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mX_test_stacked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_stacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_stacked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_stacked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "#17#Evaluate Function Call\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#load distinguishers\n",
    "json_file = open('FINAL_VULNERABLE_10_depth_3.json','r');\n",
    "json_model = json_file.read();\n",
    "\n",
    "net20 = model_from_json(json_model);\n",
    "\n",
    "net20.load_weights('FINAL_VULNERABLE_10_depth_3.h5');\n",
    "\n",
    "X_test_stacked, Y_test_stacked = make_train_data(100000, num_rounds)\n",
    "evaluate(net20, X_test_stacked, Y_test_stacked);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
