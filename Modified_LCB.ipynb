{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1#Header\n",
    "import csv\n",
    "import numpy as np\n",
    "import os \n",
    "from os import urandom\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2#Defining Global Variables\n",
    "num_rounds = 20\n",
    "m = 0\n",
    "o = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3#Defining WORDSIZE\n",
    "def WORD_SIZE():\n",
    "    return(16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4#Defining S-Box\n",
    "s_box_mapping_np = np.array([12, 5, 6, 11, 9, 0, 10, 13, 3, 14, 15, 8, 4, 7, 1, 2], dtype=np.uint8)\n",
    "\n",
    "def s_box(input_bits):\n",
    "    input_bits_int = int(input_bits)\n",
    "    output_bits_int = s_box_mapping_np[input_bits_int]\n",
    "    return output_bits_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5#Defining P-Box\n",
    "def decimal_to_binary_list(value, num_bits=4):\n",
    "    return np.array([int(x) for x in format(value, f'0{num_bits}b')], dtype=np.uint8)\n",
    "\n",
    "def p_box(c_decimal, d_decimal):\n",
    "    c = decimal_to_binary_list(c_decimal)\n",
    "    d = decimal_to_binary_list(d_decimal)\n",
    "\n",
    "    e = np.zeros(8, dtype=np.uint8)\n",
    "\n",
    "    e[0] = c[0]\n",
    "    e[1] = d[0]\n",
    "    e[2] = c[3]\n",
    "    e[3] = d[3]\n",
    "    e[4] = c[1]\n",
    "    e[5] = d[1]\n",
    "    e[6] = c[2]\n",
    "    e[7] = d[2]\n",
    "\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6#Defining L-Box\n",
    "def l_box(f, g):\n",
    "    if len(f) != 8 or len(g) != 8:\n",
    "        raise ValueError(\"Both input arrays f and g should have exactly 8 elements\")\n",
    "\n",
    "    h = np.zeros(16, dtype=np.uint8)\n",
    "    h[0] = f[0]\n",
    "    h[1] = g[0]\n",
    "    h[2] = f[7]\n",
    "    h[3] = g[7]\n",
    "    h[4] = f[1]\n",
    "    h[5] = g[1]\n",
    "    h[6] = f[6]\n",
    "    h[7] = g[6]\n",
    "    h[8] = f[2]\n",
    "    h[9] = g[2]\n",
    "    h[10] = f[5]\n",
    "    h[11] = g[5]\n",
    "    h[12] = f[3]\n",
    "    h[13] = g[3]\n",
    "    h[14] = f[4]\n",
    "    h[15] = g[4]\n",
    "    #print(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7#Defining F-function for Right Side of Plaintext\n",
    "def binary_array_to_integer(output):\n",
    "    int_output = ''.join(map(str, output))\n",
    "    return int(int_output, 2)\n",
    "\n",
    "def f_function(x, key, d):\n",
    "    q=0\n",
    "    global m\n",
    "    if isinstance(x, int):\n",
    "        x = [x]\n",
    "    input_parts = np.zeros((len(x), 4), dtype=np.uint16)\n",
    "    for i, val in enumerate(x):\n",
    "        input_parts[i] = np.array([val >> 12, (val >> 8) & 0xF, (val >> 4) & 0xF, val & 0xF])\n",
    "    \n",
    "    s_box_outputs = np.array([[s_box(element) for element in part] for part in input_parts])\n",
    "    p_box_outputs = np.zeros((len(x), 2, 8), dtype=np.uint8)\n",
    "    for i in range(len(x)):\n",
    "        p_box_outputs[i] = np.array([p_box(s_box_outputs[i][0], s_box_outputs[i][1]), p_box(s_box_outputs[i][2], s_box_outputs[i][3])])\n",
    "    \n",
    "    final_outputs = np.zeros(len(x), dtype=np.uint32)\n",
    "    for i in range(len(x)):\n",
    "        final_output = np.array(l_box(p_box_outputs[i][0], p_box_outputs[i][1]))\n",
    "        k = key[q][(m+1) % 4]\n",
    "        output = final_output ^ k\n",
    "        output = binary_array_to_integer(output)\n",
    "        final_outputs[i] = output\n",
    "        q +=1 \n",
    "    if (m < 2):\n",
    "            m +=2\n",
    "    else:\n",
    "            m = 0\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8#Defining F-function for Left Side of Plaintext\n",
    "def binary_array_to_integer(output):\n",
    "    int_output = ''.join(map(str, output))\n",
    "    return int(int_output, 2)\n",
    "\n",
    "def ff_function(x, key, d):\n",
    "    q=0\n",
    "    global o\n",
    "    if isinstance(x, int):\n",
    "        x = [x]\n",
    "        \n",
    "    input_parts = np.zeros((len(x), 4), dtype=np.uint16)\n",
    "    for i, val in enumerate(x):\n",
    "        input_parts[i] = np.array([val >> 12, (val >> 8) & 0xF, (val >> 4) & 0xF, val & 0xF])\n",
    "   \n",
    "    s_box_outputs = np.array([[s_box(element) for element in part] for part in input_parts])\n",
    "    p_box_outputs = np.zeros((len(x), 2, 8), dtype=np.uint8)\n",
    "    for i in range(len(x)):\n",
    "        p_box_outputs[i] = np.array([p_box(s_box_outputs[i][0], s_box_outputs[i][1]), p_box(s_box_outputs[i][2], s_box_outputs[i][3])])\n",
    "    \n",
    "    final_outputs = np.zeros(len(x), dtype=np.uint32)\n",
    "    for i in range(len(x)):\n",
    "        final_output = np.array(l_box(p_box_outputs[i][0], p_box_outputs[i][1]))\n",
    "        k = key[q][o % 4]\n",
    "        output = final_output ^ k\n",
    "        output = binary_array_to_integer(output)\n",
    "        final_outputs[i] = output\n",
    "        q +=1 \n",
    "    if (o < 2):\n",
    "            o +=2\n",
    "    else:\n",
    "            o = 0\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9#Convert the ciphertext pairs into Binary array\n",
    "def convert_to_binary(row):\n",
    "    bin_array = np.zeros(64, dtype=np.uint8)\n",
    "    for i, num in enumerate(row):\n",
    "        binary_str = format(num, '016b')\n",
    "        for j, b in enumerate(binary_str):\n",
    "            bin_array[i * 16 + j] = int(b)\n",
    "    return bin_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10#Encryption Function\n",
    "def lcb_encrypt(plaintext, key, rounds, d):\n",
    "    \n",
    "    left_plaintext = np.uint16(plaintext[0])\n",
    "    right_plaintext = np.uint16(plaintext[1])\n",
    "    L, R = left_plaintext, right_plaintext\n",
    "\n",
    "    n = 0\n",
    "    \n",
    "    while n < rounds:\n",
    "        L, R = f_function(R, key, d), ff_function(L, key, d)\n",
    "        n += 1\n",
    "    print(\"Encryption done per round\")    \n",
    "    return (L, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11#Fuction for generation of keys\n",
    "import random\n",
    "\n",
    "def generate_hex_keys(num_keys, length=16):\n",
    "    hex_chars = \"0123456789ABCDEF\"\n",
    "    keys_str = [\"\".join(random.choices(hex_chars, k=length)) for _ in range(num_keys)]\n",
    "\n",
    "    return keys_str\n",
    "\n",
    "\n",
    "def to_binary(value, bits):\n",
    "    return format(value, f'0{bits}b')\n",
    "\n",
    "def generate_round_keys(num_keys):\n",
    "    random_keys_hex = generate_hex_keys(num_keys)\n",
    "    round_keys = []\n",
    "    \n",
    "    for random_key_hex in random_keys_hex:\n",
    "        random_key = int(random_key_hex, 16)\n",
    "\n",
    "        K1 = (random_key >> 48) & 0xFFFF\n",
    "        K2 = (random_key >> 32) & 0xFFFF\n",
    "        K3 = (random_key >> 16) & 0xFFFF\n",
    "        K4 = random_key & 0xFFFF\n",
    "        \n",
    "        k1_bin = to_binary(K1, 16)\n",
    "        k2_bin = to_binary(K2, 16)\n",
    "        k3_bin = to_binary(K3, 16)\n",
    "        k4_bin = to_binary(K4, 16)\n",
    "\n",
    "        k1_np_array = np.array([int(bit) for bit in k1_bin])\n",
    "        k2_np_array = np.array([int(bit) for bit in k2_bin])\n",
    "        k3_np_array = np.array([int(bit) for bit in k3_bin])\n",
    "        k4_np_array = np.array([int(bit) for bit in k4_bin])\n",
    "\n",
    "        round_key = np.array([k1_np_array, k2_np_array, k3_np_array, k4_np_array])\n",
    "        round_keys.append(round_key)\n",
    "    round_key = np.array(round_keys)\n",
    "    print(\"Key generation done\")\n",
    "    return round_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12#Make dataset\n",
    "\n",
    "def make_train_data(n, nr, diff=(0x0009,0)):\n",
    "  Y = np.frombuffer(urandom(n), dtype=np.uint8);\n",
    "  Y = Y & 1;\n",
    "  plaintext = np.frombuffer(urandom(4*n), dtype=np.uint32);\n",
    "  plain0l = np.empty(n, dtype=np.uint16)\n",
    "  plain0r = np.empty(n, dtype=np.uint16)\n",
    "  \n",
    "  for i in range(n):\n",
    "    plain0l[i] = (plaintext[i] >> 16) & 0xffff\n",
    "    plain0r[i] = plaintext[i] & 0xffff\n",
    "  \n",
    "  plain1l = plain0l ^ diff[0]; plain1r = plain0r ^ diff[1];\n",
    "  \n",
    "  num_rand_samples = np.sum(Y==0);\n",
    "  plain1l[Y==0] = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  plain1r[Y==0] = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  \n",
    "  round_key = generate_round_keys(n)\n",
    "  \n",
    "  ctdata0l, ctdata0r = lcb_encrypt((plain0l, plain0r), round_key, nr, n)\n",
    "  ctdata1l, ctdata1r = lcb_encrypt((plain1l, plain1r), round_key, nr, n)\n",
    "  print(\"All encryption done\")\n",
    "  ctdata = np.vstack((ctdata0l, ctdata0r, ctdata1l, ctdata1r)).T\n",
    "  X = np.array([convert_to_binary(row) for row in ctdata])\n",
    "  print(X)\n",
    "  return(X,Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13#Creation of Model\n",
    "\n",
    "from pickle import dump\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import Dense, Conv1D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dropout\n",
    "\n",
    "dropout_rate = 0.5;\n",
    "bs = 2000;\n",
    "wdir = './freshly_trained_nets/'\n",
    "\n",
    "def cyclic_lr(num_epochs, high_lr, low_lr):\n",
    "  res = lambda i: low_lr + ((num_epochs-1) - i % num_epochs)/(num_epochs-1) * (high_lr - low_lr);\n",
    "  return(res);\n",
    "\n",
    "def make_checkpoint(datei):\n",
    "  res = ModelCheckpoint(datei, monitor='val_loss', save_best_only = True);\n",
    "  return(res);\n",
    "\n",
    "#make residual tower of convolutional blocks\n",
    "def make_resnet(num_blocks=2, num_filters=32, num_outputs=1, d1=64, d2=64, word_size=16, ks=3,depth=5, reg_param=0.0001, final_activation='sigmoid'):\n",
    "  #Input and preprocessing layers\n",
    "  inp = Input(shape=(num_blocks * word_size * 2,));\n",
    "  rs = Reshape((2 * num_blocks, word_size))(inp);\n",
    "  perm = Permute((2,1))(rs);\n",
    "  #add a single residual layer that will expand the data to num_filters channels\n",
    "  #this is a bit-sliced layer\n",
    "  conv0 = Conv1D(num_filters, kernel_size=1, padding='same', kernel_regularizer=l2(reg_param))(perm);\n",
    "  conv0 = BatchNormalization()(conv0);\n",
    "  conv0 = Activation('relu')(conv0);\n",
    "  #add residual blocks\n",
    "  shortcut = conv0;\n",
    "  for i in range(depth):\n",
    "    conv1 = Conv1D(num_filters, kernel_size=ks, padding='same', kernel_regularizer=l2(reg_param))(shortcut);\n",
    "    conv1 = BatchNormalization()(conv1);\n",
    "    conv1 = Activation('relu')(conv1);\n",
    "    conv2 = Conv1D(num_filters, kernel_size=ks, padding='same',kernel_regularizer=l2(reg_param))(conv1);\n",
    "    conv2 = BatchNormalization()(conv2);\n",
    "    conv2 = Activation('relu')(conv2);\n",
    "    conv2 = Dropout(dropout_rate)(conv2)\n",
    "    shortcut = Add()([shortcut, conv2]);\n",
    "    \n",
    "  #add prediction head\n",
    "  flat1 = Flatten()(shortcut);\n",
    "  dense1 = Dense(d1,kernel_regularizer=l2(reg_param))(flat1);\n",
    "  dense1 = BatchNormalization()(dense1);\n",
    "  dense1 = Activation('relu')(dense1);\n",
    "  dense1 = Dropout(dropout_rate)(dense1)  # Add dropout layer after the first dense layer\n",
    "  dense2 = Dense(d2, kernel_regularizer=l2(reg_param))(dense1);\n",
    "  dense2 = Dropout(dropout_rate)(dense2)\n",
    "  dense2 = BatchNormalization()(dense2);\n",
    "  dense2 = Activation('relu')(dense2);\n",
    "  out = Dense(num_outputs, activation=final_activation, kernel_regularizer=l2(reg_param))(dense2);\n",
    "  model = Model(inputs=inp, outputs=out);\n",
    "  return(model);\n",
    "\n",
    "def train_LCB_distinguisher(num_epochs, num_rounds, depth):\n",
    "    #create the network\n",
    "    print(num_rounds)\n",
    "    print(depth)\n",
    "    net = make_resnet(depth=depth, reg_param=0.00007);\n",
    "    opt = SGD(learning_rate=0.00001, momentum=0.5)\n",
    "    net.compile(optimizer= opt,loss='binary_crossentropy',metrics=['acc']);\n",
    "    #net.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc']);\n",
    "    #generate training and validation data\n",
    "    X, Y = make_train_data(10000000,num_rounds);\n",
    "    X_eval, Y_eval = make_train_data(1000000, num_rounds);\n",
    "    #set up model checkpoint\n",
    "    check = make_checkpoint(wdir+'FINAL_MODIFIED_1C_'+str(num_rounds)+'_depth_'+str(depth)+'.h5');\n",
    "    #create learnrate schedule\n",
    "    lr = LearningRateScheduler(cyclic_lr(10,0.00004, 0.000019));\n",
    "    #train and evaluate\n",
    "    #print(X_eval)\n",
    "    h = net.fit(X,Y,epochs=num_epochs,batch_size=bs,validation_data=(X_eval, Y_eval), callbacks=[lr,check]);\n",
    "    np.save(wdir+'h'+str(num_rounds)+'r_depth'+str(depth)+'.npy', h.history['val_acc']);\n",
    "    np.save(wdir+'h'+str(num_rounds)+'r_depth'+str(depth)+'.npy', h.history['val_loss']);\n",
    "    dump(h.history,open(wdir+'hist'+str(num_rounds)+'r_depth'+str(depth)+'.p','wb'));\n",
    "    print(\"Best validation accuracy: \", np.max(h.history['val_acc']));\n",
    "    return(net, h);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "3\n",
      "Key generation done\n",
      "Encryption done per round\n",
      "Encryption done per round\n",
      "All encryption done\n",
      "[[0 1 0 ... 1 1 1]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [1 1 0 ... 1 1 1]\n",
      " ...\n",
      " [1 1 0 ... 1 0 0]\n",
      " [1 0 0 ... 1 0 1]\n",
      " [0 0 1 ... 1 1 1]]\n",
      "Key generation done\n",
      "Encryption done per round\n",
      "Encryption done per round\n",
      "All encryption done\n",
      "[[1 1 1 ... 0 0 1]\n",
      " [1 0 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 0 1]\n",
      " ...\n",
      " [1 0 0 ... 1 0 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [1 0 1 ... 1 1 1]]\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 702s 350ms/step - loss: 0.8128 - acc: 0.5033 - val_loss: 0.7179 - val_acc: 0.5403 - lr: 4.0000e-05\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 717s 359ms/step - loss: 0.7979 - acc: 0.5086 - val_loss: 0.7111 - val_acc: 0.5614 - lr: 3.7667e-05\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 713s 357ms/step - loss: 0.7870 - acc: 0.5139 - val_loss: 0.7057 - val_acc: 0.5805 - lr: 3.5333e-05\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 696s 348ms/step - loss: 0.7789 - acc: 0.5186 - val_loss: 0.7009 - val_acc: 0.5982 - lr: 3.3000e-05\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 703s 352ms/step - loss: 0.7719 - acc: 0.5231 - val_loss: 0.6967 - val_acc: 0.6143 - lr: 3.0667e-05\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 696s 348ms/step - loss: 0.7663 - acc: 0.5271 - val_loss: 0.6927 - val_acc: 0.6295 - lr: 2.8333e-05\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 704s 352ms/step - loss: 0.7612 - acc: 0.5311 - val_loss: 0.6891 - val_acc: 0.6431 - lr: 2.6000e-05\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 704s 352ms/step - loss: 0.7567 - acc: 0.5348 - val_loss: 0.6857 - val_acc: 0.6557 - lr: 2.3667e-05\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 715s 357ms/step - loss: 0.7525 - acc: 0.5382 - val_loss: 0.6827 - val_acc: 0.6671 - lr: 2.1333e-05\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 721s 360ms/step - loss: 0.7487 - acc: 0.5416 - val_loss: 0.6798 - val_acc: 0.6779 - lr: 1.9000e-05\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 707s 353ms/step - loss: 0.7433 - acc: 0.5468 - val_loss: 0.6734 - val_acc: 0.7008 - lr: 4.0000e-05\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 697s 349ms/step - loss: 0.7358 - acc: 0.5536 - val_loss: 0.6670 - val_acc: 0.7232 - lr: 3.7667e-05\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 695s 347ms/step - loss: 0.7284 - acc: 0.5612 - val_loss: 0.6603 - val_acc: 0.7449 - lr: 3.5333e-05\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 698s 349ms/step - loss: 0.7211 - acc: 0.5688 - val_loss: 0.6536 - val_acc: 0.7655 - lr: 3.3000e-05\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 696s 348ms/step - loss: 0.7140 - acc: 0.5766 - val_loss: 0.6468 - val_acc: 0.7849 - lr: 3.0667e-05\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 695s 348ms/step - loss: 0.7069 - acc: 0.5846 - val_loss: 0.6399 - val_acc: 0.8034 - lr: 2.8333e-05\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 693s 347ms/step - loss: 0.6996 - acc: 0.5926 - val_loss: 0.6330 - val_acc: 0.8200 - lr: 2.6000e-05\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 694s 347ms/step - loss: 0.6924 - acc: 0.6008 - val_loss: 0.6263 - val_acc: 0.8351 - lr: 2.3667e-05\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 698s 349ms/step - loss: 0.6858 - acc: 0.6084 - val_loss: 0.6199 - val_acc: 0.8480 - lr: 2.1333e-05\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 701s 350ms/step - loss: 0.6792 - acc: 0.6160 - val_loss: 0.6137 - val_acc: 0.8592 - lr: 1.9000e-05\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 705s 353ms/step - loss: 0.6690 - acc: 0.6278 - val_loss: 0.5996 - val_acc: 0.8817 - lr: 4.0000e-05\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 705s 352ms/step - loss: 0.6539 - acc: 0.6456 - val_loss: 0.5847 - val_acc: 0.8995 - lr: 3.7667e-05\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 705s 353ms/step - loss: 0.6382 - acc: 0.6641 - val_loss: 0.5695 - val_acc: 0.9135 - lr: 3.5333e-05\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 709s 354ms/step - loss: 0.6218 - acc: 0.6832 - val_loss: 0.5546 - val_acc: 0.9233 - lr: 3.3000e-05\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 712s 356ms/step - loss: 0.6057 - acc: 0.7017 - val_loss: 0.5399 - val_acc: 0.9302 - lr: 3.0667e-05\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 705s 352ms/step - loss: 0.5901 - acc: 0.7195 - val_loss: 0.5260 - val_acc: 0.9347 - lr: 2.8333e-05\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 705s 352ms/step - loss: 0.5750 - acc: 0.7364 - val_loss: 0.5136 - val_acc: 0.9383 - lr: 2.6000e-05\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 700s 350ms/step - loss: 0.5608 - acc: 0.7523 - val_loss: 0.5013 - val_acc: 0.9411 - lr: 2.3667e-05\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 707s 354ms/step - loss: 0.5481 - acc: 0.7663 - val_loss: 0.4908 - val_acc: 0.9431 - lr: 2.1333e-05\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 709s 355ms/step - loss: 0.5364 - acc: 0.7788 - val_loss: 0.4813 - val_acc: 0.9442 - lr: 1.9000e-05\n",
      "Best validation accuracy:  0.9441750049591064\n"
     ]
    }
   ],
   "source": [
    "#14#Training the Model\n",
    "#FINAL_MODIFIED\n",
    "num_epochs = 30\n",
    "depth = 3\n",
    "trained_net, history = train_LCB_distinguisher(num_epochs, num_rounds, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL_MODIFIED1C_20_depth_3.json\n"
     ]
    }
   ],
   "source": [
    "#15#Create JSON File \n",
    "# Convert the model architecture to JSON format\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "model_json = trained_net.to_json()\n",
    "\n",
    "# Save the model architecture as a JSON file (optional)\n",
    "filename = f'FINAL_MODIFIED_1C_20_depth_3.json'\n",
    "print(filename)\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(json.loads(model_json), json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16#Evaluate Function\n",
    "def evaluate(net,X,Y):\n",
    "    Z = net.predict(X,batch_size=4000).flatten();\n",
    "    Zbin = (Z > 0.5);\n",
    "    diff = Y - Z; mse = np.mean(diff*diff);\n",
    "    n = len(Z); n0 = np.sum(Y==0); n1 = np.sum(Y==1);\n",
    "    acc = np.sum(Zbin == Y) / n;\n",
    "    tpr = np.sum(Zbin[Y==1]) / n1;\n",
    "    tnr = np.sum(Zbin[Y==0] == 0) / n0;\n",
    "    mreal = np.median(Z[Y==1]);\n",
    "    high_random = np.sum(Z[Y==0] > mreal) / n0;\n",
    "    print(\"Accuracy: \", acc, \"TPR: \", tpr, \"TNR: \", tnr, \"MSE:\", mse);\n",
    "    print(\"Percentage of random pairs with score higher than median of real pairs:\", 100*high_random);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key generation done\n",
      "Encryption done per round\n",
      "Encryption done per round\n",
      "All encryption done\n",
      "[[0 0 0 ... 1 1 1]\n",
      " [0 1 0 ... 0 0 1]\n",
      " [1 1 0 ... 1 0 1]\n",
      " ...\n",
      " [1 0 0 ... 0 1 0]\n",
      " [1 0 0 ... 0 1 1]\n",
      " [0 1 0 ... 1 1 1]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13256\\1325599212.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mX_test_stacked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_stacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_stacked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_stacked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "#17#Evaluate Function Call\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#load distinguishers\n",
    "json_file = open('FINAL_MODIFIED_1C_20_depth_3.json','r');\n",
    "json_model = json_file.read();\n",
    "\n",
    "net20 = model_from_json(json_model);\n",
    "\n",
    "net20.load_weights('FINAL_MODIFIED_1C_20_depth_3.h5');\n",
    "\n",
    "X_test_stacked, Y_test_stacked = make_train_data(100000, num_rounds)\n",
    "evaluate(net20, X_test_stacked, Y_test_stacked);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
